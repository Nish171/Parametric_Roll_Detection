SETUP TIME =  4.239079475402832
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 1200, 256)         267264    
                                                                 
 lstm_1 (LSTM)               (None, 256)               525312    
                                                                 
 dense (Dense)               (None, 64)                16448     
                                                                 
 dense_1 (Dense)             (None, 1)                 65        
                                                                 
=================================================================
Total params: 809,089
Trainable params: 809,089
Non-trainable params: 0
_________________________________________________________________
MODEL LOAD TIME =  4.8507208824157715
DATASET TIME =  5.73488187789917
Running inference for Batch: 1
SETUP TIME =  4.2093284130096436
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 1200, 256)         267264    
                                                                 
 lstm_1 (LSTM)               (None, 256)               525312    
                                                                 
 dense (Dense)               (None, 64)                16448     
                                                                 
 dense_1 (Dense)             (None, 1)                 65        
                                                                 
=================================================================
Total params: 809,089
Trainable params: 809,089
Non-trainable params: 0
_________________________________________________________________
MODEL LOAD TIME =  5.254270792007446
DATASET TIME =  5.680634021759033
Running inference for Batch: 1
Inference time: 69.41902422904968
Running inference for Batch: 2
Inference time: 59.65736269950867
Running inference for Batch: 3
Inference time: 65.95933747291565
Running inference for Batch: 4
Inference time: 67.3231680393219
Running inference for Batch: 5
Inference time: 67.00269436836243
Running inference for Batch: 6
Inference time: 67.997629404068
Running inference for Batch: 7
Inference time: 64.71319079399109
Running inference for Batch: 8
Inference time: 65.69085240364075
Running inference for Batch: 9
Inference time: 68.4701201915741
Running inference for Batch: 10
Inference time: 68.82305431365967
Running inference for Batch: 11
Inference time: 62.468162536621094
Running inference for Batch: 12
Inference time: 60.54976463317871
Running inference for Batch: 13
Inference time: 68.37628650665283
Running inference for Batch: 14
Inference time: 67.7603805065155
Running inference for Batch: 15
Inference time: 35.62400197982788
Average Inference time for Validation set with batch size 64 and out_dim 1200  = 63.989002005259195
Running inference for Batch: 1
Inference time: 63.579790115356445
Running inference for Batch: 2
Inference time: 68.37915325164795
Running inference for Batch: 3
Inference time: 68.85711860656738
Running inference for Batch: 4
Inference time: 68.45482540130615
Running inference for Batch: 5
Inference time: 68.43023085594177
Running inference for Batch: 6
Inference time: 68.53367900848389
Running inference for Batch: 7
Inference time: 68.53129696846008
Running inference for Batch: 8
Inference time: 68.60691857337952
Running inference for Batch: 9
Inference time: 68.5790503025055
Running inference for Batch: 10
Inference time: 69.15929007530212
Running inference for Batch: 11
Inference time: 68.41103100776672
Running inference for Batch: 12
Inference time: 68.40808153152466
Running inference for Batch: 13
Inference time: 68.92455530166626
Running inference for Batch: 14
Inference time: 68.47877979278564
Running inference for Batch: 15
Inference time: 35.63958406448364
Average Inference time for Test set with batch size 64 and out_dim 1200  = 66.06489232381185
SETUP TIME =  306.85135412216187
Model: "sequential"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 lstm (LSTM)                 (None, 1200, 256)         267264    
                                                                 
 lstm_1 (LSTM)               (None, 256)               525312    
                                                                 
 dense (Dense)               (None, 64)                16448     
                                                                 
 dense_1 (Dense)             (None, 1)                 65        
                                                                 
=================================================================
Total params: 809,089
Trainable params: 809,089
Non-trainable params: 0
_________________________________________________________________
MODEL LOAD TIME =  6.8366241455078125
DATASET TIME =  21.201338291168213
Running inference for Batch: 1
Inference time: 71.14729714393616
Running inference for Batch: 2
Inference time: 69.00000309944153
Running inference for Batch: 3
Inference time: 69.1937963962555
Running inference for Batch: 4
Inference time: 69.04993677139282
Running inference for Batch: 5
Inference time: 68.52867078781128
Running inference for Batch: 6
Inference time: 68.41122436523438
Running inference for Batch: 7
Inference time: 68.14195847511292
Running inference for Batch: 8
Inference time: 66.64886236190796
Running inference for Batch: 9
Inference time: 66.54221153259277
Running inference for Batch: 10
Inference time: 69.26241612434387
Running inference for Batch: 11
Inference time: 68.99867343902588
Running inference for Batch: 12
Inference time: 63.394492864608765
Running inference for Batch: 13
Inference time: 69.35471677780151
Running inference for Batch: 14
Inference time: 64.68554019927979
Running inference for Batch: 15
Inference time: 36.347232818603516
Average Inference time for Validation set with batch size 64 and out_dim 1200  = 65.9138022104899
Running inference for Batch: 1
Inference time: 66.68674993515015
Running inference for Batch: 2
Inference time: 67.8660900592804
Running inference for Batch: 3
Inference time: 69.2918028831482
Running inference for Batch: 4
Inference time: 64.5788562297821
Running inference for Batch: 5
Inference time: 67.98984122276306
Running inference for Batch: 6
Inference time: 66.71051096916199
Running inference for Batch: 7
Inference time: 67.74255609512329
Running inference for Batch: 8
Inference time: 68.95412707328796
Running inference for Batch: 9
Inference time: 68.06538128852844
Running inference for Batch: 10
Inference time: 63.39812970161438
Running inference for Batch: 11
Inference time: 69.10666823387146
Running inference for Batch: 12
Inference time: 68.83488512039185
Running inference for Batch: 13
Inference time: 68.92699933052063
Running inference for Batch: 14
Inference time: 68.85366439819336
Running inference for Batch: 15
Inference time: 36.26270842552185
Average Inference time for Test set with batch size 64 and out_dim 1200  = 65.55126473108928
