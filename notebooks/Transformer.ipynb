{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NLHbcqBSsJtl"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# os.chdir('..')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "try: \n",
        "  drive.mount('/content/drive')\n",
        "except:\n",
        "  print('Drive already mounted')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOZjP2mwsUH-",
        "outputId": "0d0fdfdb-d347-4682-969c-eeb3e7526c82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/DDP/Parametric_Roll_Detection\")"
      ],
      "metadata": {
        "id": "iocLu05XsnBJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlEB1DfLsJto"
      },
      "outputs": [],
      "source": [
        "from src.data.Dataset import Dataset as DS\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YsnQ4sS8sJto"
      },
      "outputs": [],
      "source": [
        "# Dataset generator\n",
        "n = 10\n",
        "m = 5\n",
        "hop = 0.25\n",
        "input_dim   = 30 * n\n",
        "pred_dim    = 30 * m\n",
        "shift       = pred_dim\n",
        "batch_size  = 16\n",
        "Data        = DS(\n",
        "                input_dim, \n",
        "                pred_dim, \n",
        "                shift, \n",
        "                skip=0.25, \n",
        "                hop=hop, \n",
        "                batch_size=batch_size,\n",
        "                in_cols=['roll']\n",
        "                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-NYpzcYsJtp"
      },
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6W43ZqxpsJtp"
      },
      "outputs": [],
      "source": [
        "# Loss functions\n",
        "# Regression loss\n",
        "MSE_loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "# Metrics\n",
        "# Regression metrics\n",
        "MAPE = tf.keras.metrics.MeanAbsolutePercentageError()\n",
        "MAE = tf.keras.metrics.MeanAbsoluteError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGnQbjoGsJtq"
      },
      "outputs": [],
      "source": [
        "INPUT_DIM = Data.xshape\n",
        "OUTPUT_DIM = Data.yshape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BD_dxELnsJtq",
        "outputId": "3578b99f-c107-40ce-a3e0-fb7c149eda00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input dim: [1200, 1]\n",
            "Output dim: [600, 1]\n"
          ]
        }
      ],
      "source": [
        "print('Input dim:', INPUT_DIM)\n",
        "print('Output dim:', OUTPUT_DIM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzGOr9bTsJtr"
      },
      "outputs": [],
      "source": [
        "# norm = tf.keras.layers.Normalization(input_shape=INPUT_DIM, axis=-1)\n",
        "# x_ds = Data.Train.map(lambda x, y: x)\n",
        "# norm.adapt(x_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MkNtzsabsJtr"
      },
      "outputs": [],
      "source": [
        "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
        "    # Normalization and Attention\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(inputs)\n",
        "    x = layers.MultiHeadAttention(\n",
        "        key_dim=head_size, num_heads=num_heads, dropout=dropout\n",
        "    )(x, x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    res = x + inputs\n",
        "\n",
        "    # Feed Forward Part\n",
        "    x = layers.LayerNormalization(epsilon=1e-6)(res)\n",
        "    x = layers.Conv1D(filters=ff_dim, kernel_size=1, activation=\"relu\")(x)\n",
        "    x = layers.Dropout(dropout)(x)\n",
        "    x = layers.Conv1D(filters=inputs.shape[-1], kernel_size=1)(x)\n",
        "    return x + res\n",
        "\n",
        "def build_model(\n",
        "    input_shape,\n",
        "    head_size,\n",
        "    num_heads,\n",
        "    ff_dim,\n",
        "    num_transformer_blocks,\n",
        "    mlp_units,\n",
        "    dropout=0,\n",
        "    mlp_dropout=0,\n",
        "):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = inputs\n",
        "    for _ in range(num_transformer_blocks):\n",
        "        x = transformer_encoder(x, head_size, num_heads, ff_dim, dropout)\n",
        "\n",
        "    x = layers.GlobalAveragePooling1D(data_format=\"channels_first\")(x)\n",
        "    for dim in mlp_units:\n",
        "        x = layers.Dense(dim, activation=\"relu\")(x)\n",
        "        x = layers.Dropout(mlp_dropout)(x)\n",
        "    outputs = layers.Dense(OUTPUT_DIM[0], activation=\"linear\")(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "input_shape = INPUT_DIM\n",
        "\n",
        "model = build_model(\n",
        "    input_shape,\n",
        "    head_size=256,\n",
        "    num_heads=4,\n",
        "    ff_dim=4,\n",
        "    num_transformer_blocks=4,\n",
        "    mlp_units=[1024],\n",
        "    mlp_dropout=0.4,\n",
        "    dropout=0.25,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa17dY4lsJts",
        "outputId": "48b800ef-a1e4-464a-e294-6d91af0d6745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_2 (InputLayer)           [(None, 1200, 1)]    0           []                               \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 1200, 1)     2           ['input_2[0][0]']                \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (MultiH  (None, 1200, 1)     7169        ['layer_normalization_8[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 1200, 1)      0           ['multi_head_attention_4[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  (None, 1200, 1)     0           ['dropout_9[0][0]',              \n",
            " mbda)                                                            'input_2[0][0]']                \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 1200, 1)     2           ['tf.__operators__.add_8[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 1200, 4)      8           ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 1200, 4)      0           ['conv1d_8[0][0]']               \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 1200, 1)      5           ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TFOpLa  (None, 1200, 1)     0           ['conv1d_9[0][0]',               \n",
            " mbda)                                                            'tf.__operators__.add_8[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 1200, 1)     2           ['tf.__operators__.add_9[0][0]'] \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (MultiH  (None, 1200, 1)     7169        ['layer_normalization_10[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 1200, 1)      0           ['multi_head_attention_5[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (TFOpL  (None, 1200, 1)     0           ['dropout_11[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_9[0][0]'] \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 1200, 1)     2           ['tf.__operators__.add_10[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 1200, 4)      8           ['layer_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 1200, 4)      0           ['conv1d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 1200, 1)      5           ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_11 (TFOpL  (None, 1200, 1)     0           ['conv1d_11[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_10[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_12 (LayerN  (None, 1200, 1)     2           ['tf.__operators__.add_11[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (MultiH  (None, 1200, 1)     7169        ['layer_normalization_12[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 1200, 1)      0           ['multi_head_attention_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_12 (TFOpL  (None, 1200, 1)     0           ['dropout_13[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_11[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_13 (LayerN  (None, 1200, 1)     2           ['tf.__operators__.add_12[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 1200, 4)      8           ['layer_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 1200, 4)      0           ['conv1d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 1200, 1)      5           ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_13 (TFOpL  (None, 1200, 1)     0           ['conv1d_13[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_12[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 1200, 1)     2           ['tf.__operators__.add_13[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (MultiH  (None, 1200, 1)     7169        ['layer_normalization_14[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 1200, 1)      0           ['multi_head_attention_7[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_14 (TFOpL  (None, 1200, 1)     0           ['dropout_15[0][0]',             \n",
            " ambda)                                                           'tf.__operators__.add_13[0][0]']\n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 1200, 1)     2           ['tf.__operators__.add_14[0][0]']\n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 1200, 4)      8           ['layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 1200, 4)      0           ['conv1d_14[0][0]']              \n",
            "                                                                                                  \n",
            " conv1d_15 (Conv1D)             (None, 1200, 1)      5           ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " tf.__operators__.add_15 (TFOpL  (None, 1200, 1)     0           ['conv1d_15[0][0]',              \n",
            " ambda)                                                           'tf.__operators__.add_14[0][0]']\n",
            "                                                                                                  \n",
            " global_average_pooling1d_1 (Gl  (None, 1200)        0           ['tf.__operators__.add_15[0][0]']\n",
            " obalAveragePooling1D)                                                                            \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 1024)         1229824     ['global_average_pooling1d_1[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 1024)         0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 600)          615000      ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,873,568\n",
            "Trainable params: 1,873,568\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=opt, loss=MSE_loss, metrics=[MAPE, MAE])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sat_gQLlsJtt",
        "outputId": "6c1c46a3-09df-4f62-c9c0-7eadd0e053a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 600)\n"
          ]
        }
      ],
      "source": [
        "for x, y in Data.Train.take(1):\n",
        "    out = model(x)\n",
        "    print(out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8xJe500sJtt"
      },
      "outputs": [],
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                                    patience=15,\n",
        "                                                    mode='min')\n",
        "\n",
        "checkpoint_filepath = 'models/transformer/02/model'\n",
        "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=False,\n",
        "    monitor='val_loss',\n",
        "    mode='min',\n",
        "    save_best_only=True)\n",
        "\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5,\n",
        "                              patience=5, min_lr=0.000001)\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"models/transformer/02/metrics\", update_freq=50)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights(checkpoint_filepath)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9A1FiSLRjAKB",
        "outputId": "4ea8198a-1146-4656-cd53-485b0a23f2e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f76fdc48ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5aiKGZusJtt",
        "outputId": "65b0bcc3-15e6-45bf-c1d0-5d254ccc7f43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "    429/Unknown - 468s 1s/step - loss: 15.4780 - mean_absolute_percentage_error: 190.5175 - mean_absolute_error: 2.4836"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 497s 1s/step - loss: 15.4780 - mean_absolute_percentage_error: 190.5175 - mean_absolute_error: 2.4836 - val_loss: 8.9717 - val_mean_absolute_percentage_error: 317.2279 - val_mean_absolute_error: 1.5055 - lr: 0.1000\n",
            "Epoch 2/100\n",
            "429/429 [==============================] - ETA: 0s - loss: 15.4784 - mean_absolute_percentage_error: 193.6977 - mean_absolute_error: 1.9366"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 492s 1s/step - loss: 15.4784 - mean_absolute_percentage_error: 193.6977 - mean_absolute_error: 1.9366 - val_loss: 8.9715 - val_mean_absolute_percentage_error: 319.4550 - val_mean_absolute_error: 1.5055 - lr: 0.1000\n",
            "Epoch 3/100\n",
            "429/429 [==============================] - ETA: 0s - loss: 15.4789 - mean_absolute_percentage_error: 193.6414 - mean_absolute_error: 1.9365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 492s 1s/step - loss: 15.4789 - mean_absolute_percentage_error: 193.6414 - mean_absolute_error: 1.9365 - val_loss: 8.9714 - val_mean_absolute_percentage_error: 321.2661 - val_mean_absolute_error: 1.5056 - lr: 0.1000\n",
            "Epoch 4/100\n",
            "429/429 [==============================] - ETA: 0s - loss: 15.4795 - mean_absolute_percentage_error: 193.4847 - mean_absolute_error: 1.9364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 492s 1s/step - loss: 15.4795 - mean_absolute_percentage_error: 193.4847 - mean_absolute_error: 1.9364 - val_loss: 8.9712 - val_mean_absolute_percentage_error: 322.5358 - val_mean_absolute_error: 1.5056 - lr: 0.1000\n",
            "Epoch 5/100\n",
            "429/429 [==============================] - ETA: 0s - loss: 15.4802 - mean_absolute_percentage_error: 193.2091 - mean_absolute_error: 1.9364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 492s 1s/step - loss: 15.4802 - mean_absolute_percentage_error: 193.2091 - mean_absolute_error: 1.9364 - val_loss: 8.9711 - val_mean_absolute_percentage_error: 323.2756 - val_mean_absolute_error: 1.5056 - lr: 0.1000\n",
            "Epoch 6/100\n",
            "429/429 [==============================] - ETA: 0s - loss: 15.4811 - mean_absolute_percentage_error: 192.8333 - mean_absolute_error: 1.9364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 492s 1s/step - loss: 15.4811 - mean_absolute_percentage_error: 192.8333 - mean_absolute_error: 1.9364 - val_loss: 8.9709 - val_mean_absolute_percentage_error: 323.6482 - val_mean_absolute_error: 1.5057 - lr: 0.1000\n",
            "Epoch 7/100\n",
            "429/429 [==============================] - ETA: 0s - loss: 15.4821 - mean_absolute_percentage_error: 192.3316 - mean_absolute_error: 1.9364"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 490s 1s/step - loss: 15.4821 - mean_absolute_percentage_error: 192.3316 - mean_absolute_error: 1.9364 - val_loss: 8.9708 - val_mean_absolute_percentage_error: 323.8903 - val_mean_absolute_error: 1.5058 - lr: 0.1000\n",
            "Epoch 8/100\n",
            "429/429 [==============================] - ETA: 0s - loss: 15.4833 - mean_absolute_percentage_error: 191.8635 - mean_absolute_error: 1.9365"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as query_layer_call_fn, query_layer_call_and_return_conditional_losses, key_layer_call_fn, key_layer_call_and_return_conditional_losses, value_layer_call_fn while saving (showing 5 of 48). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: models/transformer/02/model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r429/429 [==============================] - 486s 1s/step - loss: 15.4833 - mean_absolute_percentage_error: 191.8635 - mean_absolute_error: 1.9365 - val_loss: 8.9707 - val_mean_absolute_percentage_error: 324.2118 - val_mean_absolute_error: 1.5059 - lr: 0.1000\n",
            "Epoch 9/100\n",
            " 57/429 [==>...........................] - ETA: 6:36 - loss: 42.9643 - mean_absolute_percentage_error: 163.4025 - mean_absolute_error: 4.7928"
          ]
        }
      ],
      "source": [
        "model.fit(Data.Train, epochs=100, validation_data=Data.Val, callbacks=[early_stopping, model_checkpoint_callback, reduce_lr, tensorboard_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UlMm2FBhsJtu"
      },
      "outputs": [],
      "source": [
        "Data.plot_example(50, model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ8l5aMlsJtw",
        "outputId": "736c323d-adf4-405b-faa3-da3268e62420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "53/53 [==============================] - 27s 491ms/step - loss: 5.7637 - mean_absolute_percentage_error: 325.7711 - mean_absolute_error: 1.1193\n",
            "62/62 [==============================] - 40s 640ms/step - loss: 7.8260 - mean_absolute_percentage_error: 259.8730 - mean_absolute_error: 1.3493\n"
          ]
        }
      ],
      "source": [
        "val_performance = model.evaluate(Data.Val)\n",
        "test_performance = model.evaluate(Data.Test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sekYIiD4sJtw",
        "outputId": "4902b106-a24a-46ff-9800-ea60fa97d651"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation MSE_loss: 5.76\n",
            "Validation MAPE:     325.77\n",
            "Validation MAE:      1.12\n",
            "Test MSE_loss:       7.83\n",
            "Test MAPE:           259.87\n",
            "Test MAE:            1.35\n"
          ]
        }
      ],
      "source": [
        "print('Validation MSE_loss: {:.2f}'.format(val_performance[0]))\n",
        "print('Validation MAPE:     {:.2f}'.format(val_performance[1]))\n",
        "print('Validation MAE:      {:.2f}'.format(val_performance[2]))\n",
        "print('Test MSE_loss:       {:.2f}'.format(test_performance[0]))\n",
        "print('Test MAPE:           {:.2f}'.format(test_performance[1]))\n",
        "print('Test MAE:            {:.2f}'.format(test_performance[2]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-FaMF0QsJtw"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "1844590946100bef83ac7cfe239ed2c4890ee2a333855b1dfdd281ca43636803"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Transformer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}